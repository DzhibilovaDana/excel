# –§–∞–π–ª: controller.py

import logging
import os
import threading
from queue import Queue
from typing import Dict, Any, List

import pandas as pd

from services import FileHandler, GeminiService
from config import ConfigManager

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

class AnalysisController(threading.Thread):
    # ... (__init__ –∏ set_model –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ...
    def __init__(
        self,
        input_path: str,
        output_dir: str,
        config: ConfigManager,
        log_queue: Queue,
        stop_event: threading.Event
    ):
        super().__init__()
        self.daemon = True
        self.input_path = input_path
        self.output_dir = output_dir
        self.config = config
        self.log_queue = log_queue
        self.stop_event = stop_event
        self.api_key = self.config.get_api_key()
        self.model_name = config.get_model_names()[0] # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        self.batch_size = self.config.get_batch_size()
        self.save_interval = self.config.get_save_interval()
        self.file_handler = FileHandler()
        self.gemini_service = None

    def set_model(self, model_name: str):
        self.model_name = model_name

    def _log(self, message: str):
        self.log_queue.put(message)

    def _update_dataframe(self, df: pd.DataFrame, results: List[Dict[str, Any]]) -> None:
        """–û–±–Ω–æ–≤–ª—è–µ—Ç DataFrame —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏, —Å–æ–ø–æ—Å—Ç–∞–≤–ª—è—è –ø–æ 'internal_comment_id'."""
        results_map = {res.get('comment_id'): res for res in results}
        
        for idx in df.index:
            comment_id = df.loc[idx, 'internal_comment_id']
            if comment_id in results_map:
                result = results_map[comment_id]
                df.loc[idx, 'llm_sentiment'] = result.get('sentiment')
                df.loc[idx, 'llm_environment'] = result.get('environment')
                df.loc[idx, 'llm_l2_factor'] = result.get('l2_factor')
                df.loc[idx, 'llm_l3_factor'] = result.get('l3_factor')
                df.loc[idx, 'llm_justification_taxonomy'] = result.get('justification_taxonomy')
                df.loc[idx, 'llm_ejm_stage'] = result.get('ejm_stage')
                df.loc[idx, 'llm_ejm_step'] = result.get('ejm_step')
                df.loc[idx, 'llm_justification_ejm'] = result.get('justification_ejm')

    def run(self):
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥, –≤—ã–ø–æ–ª–Ω—è–µ–º—ã–π –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ.
        –†–µ–∞–ª–∏–∑—É–µ—Ç –≤—Å—é –ª–æ–≥–∏–∫—É –∞–Ω–∞–ª–∏–∑–∞ —Ñ–∞–π–ª–∞ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏—è.
        """
        df = None # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º DataFrame
        try:
            self._log("‚ñ∂Ô∏è –ö–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä –∞–Ω–∞–ª–∏–∑–∞ –∑–∞–ø—É—â–µ–Ω...")
            
            self.gemini_service = GeminiService(api_key=self.api_key, model_name=self.model_name)
            
            base_filename = os.path.splitext(os.path.basename(self.input_path))[0]
            output_csv_path = os.path.join(self.output_dir, f"{base_filename}_processed_intermediate.csv")
            output_xlsx_path = os.path.join(self.output_dir, f"{base_filename}_processed_final.xlsx")

            # --- –ò–ó–ú–ï–ù–ï–ù–ù–ê–Ø –õ–û–ì–ò–ö–ê –ó–ê–ì–†–£–ó–ö–ò ---
            df = self.file_handler.load_data(self.input_path, output_csv_path)
            total_rows = len(df)
            
            result_columns = [
                'llm_sentiment', 'llm_environment', 'llm_l2_factor', 'llm_l3_factor',
                'llm_justification_taxonomy', 'llm_ejm_stage', 'llm_ejm_step', 'llm_justification_ejm'
            ]
            for col in result_columns:
                if col not in df.columns:
                    df[col] = ""
            df[result_columns] = df[result_columns].fillna("").astype(str)
            
            # --- –õ–û–ì–ò–ö–ê –í–û–ó–û–ë–ù–û–í–õ–ï–ù–ò–Ø ---
            # –§–∏–ª—å—Ç—Ä—É–µ–º —Å—Ç—Ä–æ–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –µ—â–µ –Ω–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã (–≥–¥–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç - –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞)
            unprocessed_df = df[df['llm_sentiment'] == ""]
            
            if len(unprocessed_df) == 0:
                self._log("‚úÖ –í—Å–µ —Å—Ç—Ä–æ–∫–∏ —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑.")
            else:
                self._log(f"–ù–∞–π–¥–µ–Ω–æ {len(unprocessed_df)} –∏–∑ {total_rows} –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Å—Ç—Ä–æ–∫ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.")

            processed_count_current_session = 0
            total_already_processed = total_rows - len(unprocessed_df)
            
            for i in range(0, len(unprocessed_df), self.batch_size):
                if self.stop_event.is_set():
                    self._log("‚èπÔ∏è –ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª –æ—Å—Ç–∞–Ω–æ–≤–∫–∏. –ü—Ä–µ—Ä—ã–≤–∞–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞...")
                    break

                batch_df = unprocessed_df.iloc[i:i + self.batch_size]
                
                batch_data_to_send = []
                comment_column_name = df.columns[1] # –í—Ç–æ—Ä–æ–π —Å—Ç–æ–ª–±–µ—Ü –ø–æ—Å–ª–µ –Ω–∞—à–µ–≥–æ internal_comment_id
                
                for _, row in batch_df.iterrows():
                    comment_text = str(row[comment_column_name]) if pd.notna(row[comment_column_name]) else ""
                    batch_data_to_send.append({'comment_id': row['internal_comment_id'], 'text': comment_text})

                start_row_num_overall = total_already_processed + i + 1
                end_row_num_overall = min(start_row_num_overall + self.batch_size - 1, total_rows)
                self._log(f"‚öôÔ∏è –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç—Ä–æ–∫ {start_row_num_overall}-{end_row_num_overall} –∏–∑ {total_rows}...")
                
                results = self.gemini_service.analyze_batch(batch_data_to_send)
                
                # –û–±–Ω–æ–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –∏—Å—Ö–æ–¥–Ω–æ–º DataFrame –ø–æ –∏–Ω–¥–µ–∫—Å–∞–º –±–∞—Ç—á–∞
                df.update(batch_df.assign(**{col: [res.get(col.replace('llm_', '')) for res in results] for col in result_columns}))
                self._update_dataframe(df.loc[batch_df.index], results)

                processed_count_current_session += len(batch_df)
                total_processed = total_already_processed + processed_count_current_session
                self._log(f"__PROGRESS__;{total_processed};{total_rows}")

                # –£—Å–ª–æ–≤–∏–µ –¥–ª—è –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
                if total_processed % self.save_interval < self.batch_size and total_processed > 0 and total_processed < total_rows:
                    self.file_handler.save_to_csv(df, output_csv_path)
                    self._log(f"üíæ –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω ({total_processed} —Å—Ç—Ä–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ).")
            
            if not self.stop_event.is_set():
                self._log("‚úÖ –ê–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö —Å—Ç—Ä–æ–∫ –∑–∞–≤–µ—Ä—à–µ–Ω.")
            
            # --- –ò–ó–ú–ï–ù–ï–ù–ù–ê–Ø –õ–û–ì–ò–ö–ê –°–û–•–†–ê–ù–ï–ù–ò–Ø ---
            self._log("–ù–∞—á–∏–Ω–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ...")
            self.file_handler.save_to_csv(df, output_csv_path)
            self._log(f"üíæ –ò—Ç–æ–≥–æ–≤—ã–π CSV —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_csv_path}")
            self.file_handler.save_to_formatted_xlsx(df, output_xlsx_path)
            self._log(f"‚ú® –ò—Ç–æ–≥–æ–≤—ã–π XLSX —Å–æ—Ö—Ä–∞–Ω–µ–Ω –∏ –æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω: {output_xlsx_path}")

        except Exception as e:
            error_message = f"–ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: {type(e).__name__} - {e}"
            logging.exception("–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ –ø–æ—Ç–æ–∫–µ –∞–Ω–∞–ª–∏–∑–∞:")
            self._log(f"üõë {error_message}")
        finally:
            if 'df' in locals() and df is not None and self.stop_event.is_set():
                self._log("–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –ø–æ—Å–ª–µ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏...")
                self.file_handler.save_to_csv(df, output_csv_path)
                self.file_handler.save_to_formatted_xlsx(df, output_xlsx_path)
                self._log(f"üíæ –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ—Å–ª–µ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ CSV –∏ XLSX.")
            self._log("__DONE__" if not self.stop_event.is_set() else "__STOPPED__")